{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2238f6dc-4462-4c86-8515-4d5cb6da17e7",
   "metadata": {},
   "source": [
    "# Building Scalable API Backends with Covalent for LLM and Generative AI Applications\n",
    "\n",
    "In this tutorial, we'll delve into the intricacies of constructing scalable API backends for Large Language Models (LLMs) and Generative AI applications. We aim to facilitate seamless collaboration between two cornerstone roles in contemporary machine learning projects: **researchers**, who innovate and experiment with models, and **engineers**, tasked with transforming these models into production-grade applications.\n",
    "\n",
    "Navigating the deployment of high-compute API endpoints, particularly for Generative AI and LLMs, often presents a myriad of challenges. From juggling multiple cloud resources to managing operational overheads and switching between disparate development environments, the endeavor can quickly escalate into a complex ordeal. This tutorial is designed to guide you through these hurdles using [Covalent](https://www.covalent.xyz/), a Pythonic workflow orchestration platform.\n",
    "\n",
    "### Key Challenges and how Covalent solves them\n",
    "- **Resource Management**: The manual management of cloud resources like GPUs is not only tedious but also prone to errors. Covalent automates this, allowing for smooth workflow management right from your Python environment.\n",
    "  \n",
    "- **Operational Overhead**: Tasks like maintaining server uptime, load balancing, and API versioning can complicate the development process. Covalent streamlines these operational aspects, freeing you to focus on development.\n",
    "  \n",
    "- **Environment Switching**: The need to switch between development, testing, and production environments can be a bottleneck, especially in agile, iterative development cycles. Covalent offers a unified environment, simplifying this transition.\n",
    "  \n",
    "- **Multi-Cloud Deployment**: With GPUs often in short supply, the ability to deploy across multiple cloud providers is increasingly crucial. Covalent supports multi-cloud orchestration, making this usually complex task straightforward.\n",
    "  \n",
    "- **Scalability**: High-compute tasks often require dynamic scaling, which can be cumbersome to manage manually. Covalent handles this automatically, adapting to the computational needs of your project.\n",
    "\n",
    "### Tutorial overview\n",
    "\n",
    "This tutorial will encompass the following steps:\n",
    "\n",
    "1. Developing a customizable Covalent [workflow designed to employ AI for news article summarization](#News-Summarization-workflow) [***researcher***],\n",
    "2. [Executing experiments on the established Covalent workflows iteratively](#Rerunning-Workflows), aiming for desirable performance outcomes [***researcher***], and\n",
    "3. [Rerunning and reusing experiments via the Streamlit application](Rerunning-workflows-via-Streamlit) [***engineer***]\n",
    "\n",
    "![NewsArch](assets/diagram.png \"News summarization AI architecture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b689ccd-c0b8-47cb-a953-489f41587075",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "This tutorial requires [PyTorch](https://pytorch.org/), [Diffusers](https://github.com/huggingface/diffusers), [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) for generative AI. [Streamlit](https://streamlit.io/) and [FastAPI](https://fastapi.tiangolo.com/) will serve to make the user experience smooth. To install all of them, simply use the `requirements.txt` file to replicate this notebook. \n",
    "\n",
    "The list of packages required to run this tutorial is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03a0c441-40ec-4353-82eb-4d395fb8e4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bs4==0.0.1\n",
      "transformers==4.31.0\n",
      "diffusers==0.19.3\n",
      "sentencepiece==0.1.99\n",
      "torch==2.0.1\n",
      "accelerate==0.21.0\n",
      "Pillow==9.5.0\n",
      "streamlit==1.25.0\n",
      "xformers==0.0.21\n",
      "emoji==2.8.0\n",
      "covalent-azurebatch-plugin==0.12.0\n",
      "fastapi==0.103.1\n",
      "uvicorn==0.18.3\n"
     ]
    }
   ],
   "source": [
    "with open(\"./requirements.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        print(line.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3846e49b-f0fa-4878-b733-5fa53c1452af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below line to install necessary libraries\n",
    "# !pip install requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "063f6e62-402f-4232-b6e2-f94568aee059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save under workflow.py\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from uuid import uuid4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer, T5Tokenizer, T5ForConditionalGeneration,\n",
    "    pipeline, AutoModelForSequenceClassification\n",
    ")\n",
    "from diffusers import DiffusionPipeline\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import covalent as ct\n",
    "import torch\n",
    "\n",
    "\n",
    "# setting loggers to info to avoid too many debug messages\n",
    "loggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\n",
    "for logger in loggers:\n",
    "    logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957bdb21-b577-4d56-99a5-b07cea92f1dc",
   "metadata": {},
   "source": [
    "# News Summarization workflow\n",
    "\n",
    "\n",
    "We first define executors to use [Azure Batch](https://github.com/AgnostiqHQ/covalent-azurebatch-plugin) as compute. Two types of executors allow us to leverage different executors for different compute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13658ad0-c002-4ef6-bc4d-ad9fed565443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save under workflow.py\n",
    "\n",
    "# define dependencies to install on remote execution\n",
    "DEPS_ALL = ct.DepsPip(\n",
    "    packages=[\n",
    "        \"transformers==4.31.0\", \"diffusers==0.19.3\", \"accelerate==0.21.0\",\n",
    "        \"cloudpickle==2.2.0\", \"sentencepiece==0.1.99\", \"torch==2.0.1\",\n",
    "        \"Pillow==9.5.0\", \"xformers==0.0.21\", \"emoji==2.8.0\", \"protobuf\"\n",
    "    ]\n",
    ")\n",
    "azure_cpu_executor = ct.executor.AzureBatchExecutor(\n",
    "    # Ensure to specify your own Azure resource information\n",
    "    pool_id=\"covalent-cpu\",\n",
    "    retries=3,\n",
    "    time_limit=600,\n",
    ")\n",
    "\n",
    "# base_image_uri points to a non-default different docker image to support use nvidia gpu\n",
    "azure_gpu_executor = ct.executor.AzureBatchExecutor(\n",
    "    # Ensure to specify your own Azure resource information\n",
    "    pool_id=\"covalent-gpu\",\n",
    "    retries=3,\n",
    "    time_limit=600,\n",
    "    base_image_uri=\"docker.io/filipbolt/covalent_azure:0.220.0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8c2d87-9d9a-4b56-ae9b-8c7b8e2668d2",
   "metadata": {},
   "source": [
    "Each electron is associated with an executor, where the computation takes place. Within this framework, less demanding tasks are allocated to the `cpu` executor, while computationally intensive tasks, like generating images from textual prompts, are designated to the `gpu` for compute resources. First, we provide the task outlines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "113c6ecd-719a-4be1-940b-d38fefe26733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save under workflow.py\n",
    "@ct.electron(executor=azure_cpu_executor)\n",
    "def extract_news_content(news_url):\n",
    "    response = requests.get(news_url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Extracting article text\n",
    "    paragraphs = soup.find_all(\"p\")\n",
    "    article = \" \".join([p.get_text() for p in paragraphs])\n",
    "    return article\n",
    "\n",
    "@ct.electron(executor=azure_cpu_executor)\n",
    "def generate_title(\n",
    "    article, model_name=\"JulesBelveze/t5-small-headline-generator\",\n",
    "    max_tokens=84, temperature=1, no_repeat_ngram_size=2\n",
    "):\n",
    "    ...\n",
    "\n",
    "@ct.electron(executor=azure_gpu_executor)\n",
    "def generate_reduced_summary(\n",
    "    article, model_name=\"t5-small\", max_length=30\n",
    "):\n",
    "    ...\n",
    "\n",
    "@ct.electron(executor=azure_cpu_executor)\n",
    "def add_title_to_image(image, title):\n",
    "    ...\n",
    "\n",
    "@ct.electron(executor=azure_gpu_executor)\n",
    "def sentiment_analysis(\n",
    "    article, model_name=\"finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "):\n",
    "    ...\n",
    "\n",
    "@ct.electron(executor=azure_cpu_executor)\n",
    "def generate_image_from_text(\n",
    "    reduced_summary, model_name=\"OFA-Sys/small-stable-diffusion-v0\", prompt=\"Impressionist image - \"\n",
    "):\n",
    "    ...\n",
    "\n",
    "@ct.electron(executor=azure_cpu_executor)\n",
    "def save_image(image, filename='image'):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f45c3-71ff-4e2f-83ae-6b45bbde67ee",
   "metadata": {},
   "source": [
    "## Covalent Workflow\n",
    "\n",
    "The workflow connects all these steps (electrons) into a workflow (lattice) into a cohesive and runnable workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dde7bfe-ead8-4b4b-b2c8-3633f0af9c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save under workflow.py\n",
    "@ct.lattice\n",
    "def news_content_curator(\n",
    "    news_url, image_generation_prefix=\"Impressionist image \",\n",
    "    summarizer_model=\"t5-small\",\n",
    "    summarizer_max_length=40,\n",
    "    title_generating_model=\"JulesBelveze/t5-small-headline-generator\",\n",
    "    image_generation_model=\"OFA-Sys/small-stable-diffusion-v0\",\n",
    "    temperature=1, max_tokens=64, no_repeat_ngram_size=2,\n",
    "    content_analysis_model=\"finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "):\n",
    "    article = extract_news_content(news_url)\n",
    "    content_property = sentiment_analysis(\n",
    "        article, model_name=content_analysis_model\n",
    "    )\n",
    "    reduced_summary = generate_reduced_summary(\n",
    "        article, model_name=summarizer_model, max_length=summarizer_max_length\n",
    "    )\n",
    "    title = generate_title(\n",
    "        article, model_name=title_generating_model,\n",
    "        temperature=temperature, max_tokens=max_tokens,\n",
    "        no_repeat_ngram_size=no_repeat_ngram_size\n",
    "    )\n",
    "    generated_image = generate_image_from_text(\n",
    "        reduced_summary, prompt=image_generation_prefix,\n",
    "        model_name=image_generation_model\n",
    "    )\n",
    "    image_with_title = add_title_to_image(generated_image, title)\n",
    "    url = save_image(image_with_title)\n",
    "    return {\n",
    "        \"content_property\": content_property, \"summary\": reduced_summary,\n",
    "        \"title\": title, \"image\": url,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc4ec17-82a8-4fab-a6f2-1e77a685d35a",
   "metadata": {},
   "source": [
    "Finally, once a lattice is defined, you must dispatch a workflow to run it. You can dispatch a lattice workflow using Covalent by calling `ct.dispatch` and providing a workflow name and parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afbe7311-28e8-4f14-8598-e3378ebec946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a659c4c8-bb63-4ebd-9c02-1c2e02b52591\n"
     ]
    }
   ],
   "source": [
    "news_url = 'https://www.quantamagazine.org/math-proof-draws-new-boundaries-around-black-hole-formation-20230816/'\n",
    "dispatch_id = ct.dispatch(news_content_curator)(news_url)\n",
    "print(dispatch_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3288e10f-b1e5-4524-bce8-cfde58b1ae84",
   "metadata": {},
   "source": [
    "The resulting workflow should look like the example below\n",
    "\n",
    "![NewsSum](assets/workflow.gif \"News summarization AI workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83556535-e8af-42ff-958b-79f7233b51f2",
   "metadata": {},
   "source": [
    "Now that the workflow successfully runs, we add more logic to the stub tasks we previously built. \n",
    "\n",
    "Generating text, images, and analyzing content via sentiment analysis can all be implemented via the `transformers` and `diffusers` frameworks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83724676-0bb2-4248-a8ce-08fa5781f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# place in workflow.py\n",
    "@ct.electron(executor=azure_gpu_executor, deps_pip=DEPS_ALL)\n",
    "def generate_title(\n",
    "    article, model_name=\"JulesBelveze/t5-small-headline-generator\",\n",
    "    max_tokens=84, temperature=1, no_repeat_ngram_size=2\n",
    "):\n",
    "    WHITESPACE_HANDLER = lambda k: re.sub(\"\\s+\", \" \", re.sub(\"\\n+\", \" \", k.strip()))\n",
    "\n",
    "    if 't5' in model_name:\n",
    "        tokenizer = T5Tokenizer.from_pretrained(\n",
    "            model_name, legacy=False\n",
    "        )\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    # Process and generate title\n",
    "    input_ids = tokenizer(\n",
    "        [WHITESPACE_HANDLER(article)], return_tensors=\"pt\",\n",
    "        padding=\"max_length\", truncation=True, max_length=384,\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids, max_length=max_tokens,\n",
    "        no_repeat_ngram_size=no_repeat_ngram_size, num_beams=4,\n",
    "        temperature=temperature\n",
    "    )[0]\n",
    "\n",
    "    return tokenizer.decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    \n",
    "@ct.electron(executor=azure_gpu_executor, deps_pip=DEPS_ALL)\n",
    "def generate_reduced_summary(\n",
    "    article, model_name=\"t5-small\", max_length=30\n",
    "):\n",
    "    if 't5' in model_name:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name + \"_tokenizer\", legacy=False)\n",
    "    else:\n",
    "        tokenizer = T5Tokenizer.from_pretrained(model_name + \"_tokenizer\")\n",
    "\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    # Encode the article and generate a title\n",
    "    input_text = \"summarize: \" + article\n",
    "    inputs = tokenizer.encode(\n",
    "        input_text, return_tensors=\"pt\", max_length=512, truncation=True\n",
    "    )\n",
    "    # Generate a title with a maximum of max_length words\n",
    "    outputs = model.generate(inputs, max_length=max_length, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "@ct.electron(executor=azure_gpu_executor, deps_pip=DEPS_ALL)\n",
    "def sentiment_analysis(\n",
    "    article,\n",
    "    model_name=\"finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "):\n",
    "    sentiment_pipeline = pipeline(\n",
    "        \"sentiment-analysis\", model=model_name,\n",
    "        padding=True, truncation=True\n",
    "    )\n",
    "    mapping = {\n",
    "        'NEU': 'neutral',\n",
    "        'NEG': 'negative',\n",
    "        'POS': 'positive'\n",
    "    }\n",
    "    label = sentiment_pipeline(article)[0][\"label\"]\n",
    "    return mapping.get(label, label)\n",
    "\n",
    "@ct.electron(executor=azure_gpu_executor, deps_pip=DEPS_ALL)\n",
    "def generate_image_from_text(reduced_summary, model_name=\"OFA-Sys/small-stable-diffusion-v0\", prompt=\"Impressionist image - \"):\n",
    "    model = DiffusionPipeline.from_pretrained(\n",
    "        model_name, safety_checker=None,\n",
    "        torch_dtype=torch.float16\n",
    "    )\n",
    "    model.enable_attention_slicing()\n",
    "    \n",
    "    # Generate image using DiffusionPipeline\n",
    "    reduced_summary = prompt + reduced_summary\n",
    "    _ = model(reduced_summary, num_inference_steps=1)\n",
    "    return model(reduced_summary).images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8590ad85-6537-49a8-a9f7-ec3b9012be03",
   "metadata": {},
   "source": [
    "The generated images and text can be patched together, and the image may then be uploaded to a cloud storage to make it easier to transfer it via an API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a010e2cf-b86f-4af1-b513-3ba8753a8d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron(executor=azure_cpu_executor, deps_pip=DEPS_ALL)\n",
    "def add_title_to_image(image, title):\n",
    "    # Create a new image with space for the title\n",
    "    new_image = Image.new(\n",
    "        \"RGB\", (image.width, image.height + 40), color=\"black\"\n",
    "    )\n",
    "    new_image.paste(image, (0, 40))\n",
    "\n",
    "    # Create a drawing context\n",
    "    draw = ImageDraw.Draw(new_image)\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    # Sanitize title to remove non-latin-1 characters\n",
    "    sanitized_title = \"\".join([i if ord(i) < 128 else \" \" for i in title])\n",
    "\n",
    "    # Split the title into multiple lines if it's too long\n",
    "    words = sanitized_title.split()\n",
    "    lines = []\n",
    "    while words:\n",
    "        line = \"\"\n",
    "        while words and font.getlength(line + words[0]) <= image.width:\n",
    "            line += words.pop(0) + \" \"\n",
    "        lines.append(line)\n",
    "\n",
    "    # Calculate position to center the text\n",
    "    y_text = 10\n",
    "    for line in lines:\n",
    "        # Calculate width and height of the text to be drawn\n",
    "        _, _, width, height = draw.textbbox(xy=(0, 0), text=line, font=font)\n",
    "        position = ((new_image.width - width) / 2, y_text)\n",
    "        draw.text(position, line, font=font, fill=\"white\")\n",
    "        y_text += height\n",
    "\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9ab8e9-f61e-4671-961e-91f520e0ae04",
   "metadata": {},
   "source": [
    "Finally, we will upload the image to Azure blob storage. The URL is used in the Streamlit app which then downloads and renders the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c5f33-9b56-45c7-b10e-6fbebb43bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Azure Storage account connection string\n",
    "connection_string = \"<your_connection_string>\"\n",
    "\n",
    "# Name of the container where you want to upload the file\n",
    "container_name = \"<your_container_name>\"\n",
    "\n",
    "# Name for the blob (file) in the container\n",
    "blob_name = \"<desired_blob_name>\"\n",
    "\n",
    "@ct.electron(executor=azure_cpu_executor, deps_pip=DEPS_ALL, files=[ft])\n",
    "def save_image(image, filename='file_destination'):\n",
    "    image.save(f\"{filename}.jpg\")\n",
    "    # Create a BlobServiceClient\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    # Get a reference to the container\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    \n",
    "    # Create or get a BlobClient to upload the file\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "\n",
    "    # Upload the file\n",
    "    with open(f\"{filename}.jpg\", \"rb\") as data:\n",
    "        blob_client.upload_blob(data)\n",
    "\n",
    "    # Set the blob's access level to Blob (public read access)\n",
    "    blob_client.set_blob_access_tier(\"Cool\")\n",
    "    blob_client.set_blob_access_policy(sas_token=None, permission=BlobSasPermissions(read=True), expiry=datetime.datetime.utcnow() + datetime.timedelta(days=365))\n",
    "\n",
    "    sas_token = generate_blob_sas(\n",
    "        account_name=blob_service_client.account_name,\n",
    "        container_name=container_name,\n",
    "        blob_name=blob_name,\n",
    "        account_key=blob_service_client.credential.account_key,\n",
    "        permission=BlobSasPermissions(read=True),\n",
    "        expiry=datetime.datetime.utcnow() + datetime.timedelta(days=365)\n",
    "    )\n",
    "    blob_url_with_sas = f\"https://{blob_service_client.account_name}.blob.core.windows.net/{container_name}/{blob_name}?{sas_token}\"\n",
    "\n",
    "    return blob_url_with_sas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473134d0-c533-45fd-9918-bd92aa9c8de2",
   "metadata": {},
   "source": [
    "# Rerunning Workflows\n",
    "\n",
    "Upon the execution of a Covalent workflow, an associated `dispatch_id` is generated, serving as a unique workflow execution identifier. This dispatch ID serves a dual purpose: it acts as a reference point for the specific workflow and also facilitates the rerun of the entire workflow. Covalent retains a record of all previously executed workflows in a **scalable database**, thus forming a comprehensive history that can be rerun using their respective dispatch IDs.\n",
    "\n",
    "[Redispatching](https://docs.covalent.xyz/docs/features/redispatch/) a workflow to summarize a different news article can be done by providing the `dispatch_id` to the `redispatch` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "264b2e78-8531-45fd-ba77-10cc978756f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a9e020a7-628f-4e3f-82fc-7e90fd379d94\n"
     ]
    }
   ],
   "source": [
    "new_url = \"https://www.quantamagazine.org/what-a-contest-of-consciousness-theories-really-proved-20230824/\"\n",
    "redispatch_id = ct.redispatch(dispatch_id)(new_url)\n",
    "print(redispatch_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922bba8f-8196-49c2-8bd0-473ffdf9af58",
   "metadata": {},
   "source": [
    "It's important to distinguish between dispatching workflows (using `ct.dispatch`) and redispatching them (using `ct.redispatch`). **Dispatching** is typically carried out during the stages of designing a new workflow, while **redispatching** involves replicating and refining a previously created and dispatched workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a159c4fd-a8ac-4e87-8c92-0d62527cc0e9",
   "metadata": {},
   "source": [
    "It's also possible to rerun a workflow while [reusing previously computed results](https://docs.covalent.xyz/docs/features/redispatch/#reuse-previously-computed-results). For instance, if you want to experiment with a different prompt for generating images from the same news article, while keeping the summarization and headline generation unchanged, you can initiate the workflow again, preserving the use of previous results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62642c3c-2054-403f-a9d5-170bd84f3f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "redispatch_id = ct.redispatch(dispatch_id, reuse_previous_results=True)(new_url, \"Cubistic image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e296642-6d4d-413b-ab32-00a0782929a0",
   "metadata": {},
   "source": [
    "Furthermore, it's possible to tailor a previously executed workflow by replacing tasks. We can achieve this by employing the `replace_electrons` feature, [which allows us to substitute one task with another](https://docs.covalent.xyz/docs/features/redispatch/#re-executing-the-workflow-with-new-input-arguments). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e93cdf93-098a-47b7-b464-659fabba20d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron(executor=azure_cpu_executor)\n",
    "def classify_news_genre(\n",
    "    article, model_name=\"abhishek/autonlp-bbc-news-classification-37229289\"\n",
    "):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        article, return_tensors=\"pt\", truncation=True, max_length=512\n",
    "    )\n",
    "    outputs = model(**inputs)\n",
    "    id2label = {\n",
    "        0: \"business\",\n",
    "        1: \"entertainment\",\n",
    "        2: \"politics\",\n",
    "        3: \"sport\",\n",
    "        4: \"tech\"\n",
    "    }\n",
    "    return id2label[outputs.logits.argmax().item()]\n",
    "\n",
    "replace_electrons = {\n",
    "    \"sentiment_analysis\": classify_news_genre\n",
    "}\n",
    "\n",
    "redispatch_id = ct.redispatch(dispatch_id, replace_electrons=replace_electrons)(\n",
    "    new_url, \"Cubistic image\", content_analysis_model=\"abhishek/autonlp-bbc-news-classification-37229289\"\n",
    ")\n",
    "print(redispatch_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c3f63c-5e34-49d8-a903-5bdc67820c37",
   "metadata": {},
   "source": [
    "# Rerunning workflows via Streamlit\n",
    "\n",
    "\n",
    "\n",
    "Instead of running and rerunning python scripts, we provide you with a [Streamlit](https://streamlit.io/) app that allows reruns simply by using a dispatch ID string. To be able to do so, we've added another layer of efficiency. A lightweight [FastAPI](https://fastapi.tiangolo.com/) server residing on the same machine as the Covalent server acts as a middleware. This server receives a JSON payload containing inputs and the dispatch ID, and forwards it to Covalent. This setup further decouples Streamlit from Covalent, allowing your Streamlit server to operate even more efficiently. \n",
    "\n",
    "\n",
    "At this point, we recommend to decouple the python code into three files:\n",
    "1. `workflow.py` containing the code to run the Covalent workflow\n",
    "2. `streamlit_app.py` containing streamlit code\n",
    "3. `fast_api.py` containing fast API code\n",
    "\n",
    "The outline of the middleware FastAPI layer can then be (`fast_api.py`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46b82422-4acf-4698-bea4-79ea406c5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as fast_api.py\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, Request\n",
    "import covalent as ct\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/news_content_curator\")\n",
    "async def news_content_api(dispatch_id: str, request: Request):\n",
    "    params = await request.json()\n",
    "    selected_content_analysis = params.pop('selected_content_analysis')\n",
    "\n",
    "    redispatch_id = ct.redispatch(\n",
    "        dispatch_id, reuse_previous_results=True,\n",
    "    )(**params)\n",
    "    return {\n",
    "        'status': 'success',\n",
    "        'dispatch_id': redispatch_id\n",
    "    }\n",
    "\n",
    "@app.get(\"/get_result\")\n",
    "async def get_result(dispatch_id: str):\n",
    "    result = ct.get_result(dispatch_id, wait=True)\n",
    "    workflow_result = result.result\n",
    "    return workflow_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ce8c63-834d-4197-ac2e-483f84caff17",
   "metadata": {},
   "source": [
    "To execute the FastAPI in a distinct Python script, you can include the subsequent code and store it as a separate script (`fast_api.py`).\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8085)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e29327-2fc4-4be0-aa51-002eda668e13",
   "metadata": {},
   "source": [
    "After saving, run it using `python fast_api.py` in a separate shell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f3507-bfb8-4afb-9210-72966f861b80",
   "metadata": {},
   "source": [
    "Now that we have the capability to execute and re-execute Covalent workflows, our goal is to offer users a user-friendly interface. Streamlit enables us to achieve precisely that! We have developed a compact Streamlit application that enables users to adjust parameters for the AI news summarization workflow mentioned earlier and trigger previously executed workflows using their dispatch IDs. The sidebar of the Streamlit app will contain the parameters, with some proposed default values, whereas the central part of the Streamlit app will serve to render the results of the Covalent workflows. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f995197b-d196-4dbe-8048-5df6d881168a",
   "metadata": {},
   "source": [
    "The Streamlit sidebar can be defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d31b26a-57b1-48fb-bedf-08b710c903d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "def create_streamlit_sidebar(\n",
    "    stable_diffusion_models, news_summary_generation,\n",
    "    headline_generation_models, sentiment_analysis_models,\n",
    "    genre_analysis_models\n",
    "):\n",
    "    with st.sidebar:\n",
    "        # Define the location of the remote fast API middleware server\n",
    "        server_location = st.text_input(\n",
    "            \"Remote server URL\", value=\"http://localhost:8085\"\n",
    "        )\n",
    "        news_article_url = st.text_input(\n",
    "            \"News article URL\",\n",
    "            value=\"https://www.quantamagazine.org/math-proof-draws-new-boundaries-around-black-hole-formation-20230816/\"  # noqa\n",
    "        )\n",
    "        st.header(\"Parameters\")\n",
    "        st.subheader(\"Image generation\")\n",
    "\n",
    "        image_generation_prefix = st.text_input(\n",
    "            \"Image generation prompt\",\n",
    "            value=\"impressionist style\"\n",
    "        )\n",
    "        image_generation_model = stable_diffusion_models[0]\n",
    "        st.subheader(\"Text summarization\")\n",
    "        summarizer_model = news_summary_generation[0]\n",
    "        summarizer_max_length = st.slider(\n",
    "            \"Summarizer length\", min_value=5, max_value=200, value=64,\n",
    "        )\n",
    "\n",
    "        st.subheader(\"Text generation parameters\")\n",
    "        title_generating_model = headline_generation_models[0]\n",
    "\n",
    "        temperature = st.slider(\n",
    "            \"Temperature\", min_value=0.0, max_value=100.0, value=1.0,\n",
    "            step=0.1\n",
    "        )\n",
    "        max_tokens = st.slider(\n",
    "            \"Max tokens\", min_value=5, max_value=200, value=64,\n",
    "        )\n",
    "        no_repeat_ngram_size = st.slider(\n",
    "            \"No repeat ngram size\", min_value=1, max_value=10, value=2,\n",
    "        )\n",
    "        st.subheader(\"Content analysis\")\n",
    "        selected_content_analysis = st.selectbox(\n",
    "            \"Content analysis option\", options=[\n",
    "                \"sentiment analysis\",\n",
    "                \"genre classification\"\n",
    "            ]\n",
    "        )\n",
    "        if selected_content_analysis == \"sentiment analysis\":\n",
    "            content_analysis_model = sentiment_analysis_models[0]\n",
    "        else:\n",
    "            content_analysis_model = genre_analysis_models[0]\n",
    "\n",
    "    return server_location, {\n",
    "        'news_url': news_article_url,\n",
    "        'image_generation_prefix': image_generation_prefix,\n",
    "        'summarizer_model': summarizer_model,\n",
    "        'summarizer_max_length': summarizer_max_length,\n",
    "        'title_generating_model': title_generating_model,\n",
    "        'image_generation_model': image_generation_model,\n",
    "        'temperature': temperature,\n",
    "        'max_tokens': max_tokens,\n",
    "        'no_repeat_ngram_size': no_repeat_ngram_size,\n",
    "        'content_analysis_model': content_analysis_model,\n",
    "        'selected_content_analysis': selected_content_analysis\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f2975c-9e60-4716-a50e-06a84b8c8941",
   "metadata": {},
   "source": [
    "The central part of the Streamlit app is designed to render results from Covalent server, using the parameters configured in the sidebar. This triggers the generation of an AI-generated summary of the news article, a proposed title, and an AI-generated image depicting the content of the news article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7c9b8e5-23ff-48f3-ad1b-dc7f97eb165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "st.title(\"News article AI summarization\")\n",
    "dispatch_id_area = st.text_area(\"Dispatch IDs\")\n",
    "\n",
    "if st.button(\"Generate image and text summary\"):\n",
    "    st.write(\"Generating...\")\n",
    "\n",
    "    container = st.container()\n",
    "    response = make_redispatch(\n",
    "        server_location, parameters, dispatch_id,\n",
    "    )\n",
    "    if response['status'] == \"error\":\n",
    "        st.write(f\"Error: {response['message']}\")\n",
    "    else:\n",
    "        redispatch_id = response['dispatch_id']\n",
    "\n",
    "        covalent_info = get_covalent_info(server_location).json()\n",
    "        address = covalent_info['address']\n",
    "        port = covalent_info['port']\n",
    "        covalent_url = f\"{address}:{port}/{redispatch_id}\"\n",
    "\n",
    "        st.write(f\"Covalent URL on remote server: http://{covalent_url}\")\n",
    "\n",
    "        with container:\n",
    "            result = get_dispatch_result(server_location, redispatch_id)\n",
    "            if result and result.json():\n",
    "                result = result.json()\n",
    "                st.subheader(\n",
    "                    \"Article generated title: \" +\n",
    "                    f\"{result['title']}\"\n",
    "                )\n",
    "                st.write(\n",
    "                    \"In terms of \" +\n",
    "                    parameters['selected_content_analysis'] +\n",
    "                    \" content is: \" + str(result['content_property'])\n",
    "                )\n",
    "\n",
    "                image_url = result['image']\n",
    "                response = requests.get(image_url, stream=True)\n",
    "                local_image = f'/tmp/{redispatch_id}.img.png'\n",
    "                with open(local_image, 'wb') as out_file:\n",
    "                    shutil.copyfileobj(response.raw, out_file)\n",
    "                st.image(local_image)\n",
    "\n",
    "                st.text_area(\n",
    "                    label=\"AI generated summary\",\n",
    "                    key=\"summary\",\n",
    "                    value=result['summary'], disabled=True\n",
    "                )\n",
    "            else:\n",
    "                st.write(\"Error with processing, check workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29810af4-a4c1-4bb4-9ff1-375432b4bf7b",
   "metadata": {},
   "source": [
    "If you saved the provided streamlit code in `streamlit_app.py`, you can run it in a separate python console by running\n",
    "\n",
    "`streamlit run streamlit_app.py`\n",
    "\n",
    "This will start the streamlit app on http://localhost:8501\n",
    "\n",
    "You can use the streamlit app as demonstrated below:\n",
    "\n",
    "![StreamlitCovalent](assets/streamlit_covalent.gif \"Streamlit + Covalent\")\n",
    "\n",
    "Generating multiple images with Streamlit via Covalent is demonstrated below\n",
    "\n",
    "![StreamlitCovalent](assets/streamlit_covalent_imagegen.gif \"Streamlit + Covalent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e721a608-6880-4e1f-a4a1-09018a69798c",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Through the integration of Covalent and Streamlit, we have developed a news content summarization application that demonstrates a smooth transition from the design of machine learning experiments to the dependable repetition and enhancement of experimental outcomes. Covalent's capability to re-execute previously performed workflows simplifies collaboration between engineers and researchers who constructed these workflows, enabling the reuse and customization of previously computed workflows. \n",
    "\n",
    "Leveraging Covalent's capabilities, we structured the application into three distinct components: 1) Covalent workflow design, 2) a FastAPI API layer that serves as an interface to Covalent, and 3) a user-friendly Streamlit interface responsible for invoking the FastAPI API layer and presenting the results in an easily comprehensible format.\n",
    "\n",
    "This tutorial aims to showcase the remarkable potential of Covalent in conjunction with Streamlit. Covalent is free and [open source](https://www.covalent.xyz/open-source/). Please visit the [Covalent documentation](https://docs.covalent.xyz/docs/) for more information and many more [tutorials](https://docs.covalent.xyz/docs/user-documentation/tutorials/). An example of the Streamlit application described here was deployed [here](https://covalentredispatch-u5xmshqomhpbtwnszya4jv.streamlit.app/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
