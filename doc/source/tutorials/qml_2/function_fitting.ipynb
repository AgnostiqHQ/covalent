{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Quantum Machine Learning\n",
    "\n",
    "In this tutorial, we'll use a combination quantum-classical algorithm in order to train a model to predict data points in a curve. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start out by importing all of the necessary python packages, including PennyLane to build the quantum circuit, matplotlib to visualize our data, and Covalent to organize, track, and dispatch our workflow."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import covalent as ct"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll start out by loading our data from a csv file. In this example, we use a gaussian curve, but any simple curve could be used."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "@ct.electron\n",
    "def load_data(filename):\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "data = load_data('gauss.txt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As is, the dataset is too large! Quantum circuits function best with smaller datasets, so we define a new function to evenly select datapoints from our csv file. The below function, reduce_data, takes the dataset and number of data points n. We choose 7 data points, but we encourage the user to vary this number and see how it impacts the algorithm's performance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "@ct.electron\n",
    "def reduce_data(data, n):\n",
    "    interval = int(len(data)/n)\n",
    "    return data[0::interval]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "red_data = reduce_data(data, 10)\n",
    "#plt.scatter(red_data[:,0], red_data[:,1])\n",
    "#plt.plot(red_data[:,0], red_data[:,1], linestyle='--')\n",
    "#plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The process of validation is an important part of machine learning. Validation involves separating your dataset into separate training and testing datasets. The training dataset is used to actually train the parameters of your model. Once your model has been sufficiently trained, its accuracy can be evaluated using the test dataset. The majority of the original dataset (usually 60-85%) is used for training data, while the remaining data (15-40%) is used for test data.\n",
    "\n",
    "In the following step, we split our reduced dataset into training and test data, and separate the X and Y columns. There are a few ways to do this, but in this example we'll use scikit-learn's train_test_split() function. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "@ct.electron\n",
    "def train_test_split(data, train_portion):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data[:,0], data[:,1], train_size=train_portion, random_state=42)\n",
    "    X_train = np.tensor(X_train)\n",
    "    X_train.requires_grad = False\n",
    "    return X_train, np.array(Y_train), np.tensor(X_test), np.array(Y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "X_train, Y_train, X_test, Y_test = train_test_split(red_data, 0.5)\n",
    "\n",
    "#plt.plot(data[:,0], data[:,1], linestyle='--')\n",
    "#plt.scatter(X_train, Y_train, label='Training Data')\n",
    "#plt.scatter(X_test, Y_test, label='Test Data')\n",
    "#plt.legend()\n",
    "#plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "@ct.electron\n",
    "def plot_data(X_train, Y_train, X_test, Y_test):\n",
    "    plt.scatter(X_train, Y_train, color='#219ebc', label='Training Data')\n",
    "    plt.scatter(X_test, Y_test, color='#fb8500', alpha=0.5, label='Test Data')\n",
    "    plt.legend()\n",
    "    plt.savefig('input_data.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "dev = qml.device('default.qubit', wires=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "dev = qml.device('default.qubit', wires=1)\n",
    "@ct.electron\n",
    "def quantum_circuit(datapoint, params):\n",
    "        datapoint = datapoint\n",
    "        params = params\n",
    "        @qml.qnode(dev)\n",
    "        def qc():\n",
    "                qml.RX(datapoint, wires=0)\n",
    "                qml.Rot(params[0], params[1], params[2], wires=0)\n",
    "                return qml.expval(qml.PauliZ(wires=0))\n",
    "        expval = qc()\n",
    "        return expval"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "@ct.electron\n",
    "def cost_fn(params):\n",
    "    #X, Y, X_test, Y_test = train_test_split(red_data, 0.5)\n",
    "    predictions = make_predictions(X_train, params)\n",
    "    total_losses = 0\n",
    "    for i in range(len(Y_train)):\n",
    "        loss = (predictions[i] - Y_train[i])**2\n",
    "        total_losses += loss\n",
    "    return total_losses\n",
    "    #return cost\n",
    "\n",
    "@ct.electron \n",
    "def update_parameters(opt, params, quantum_circuit):\n",
    "    params = opt.step(cost_fn,params)\n",
    "    return params\n",
    "\n",
    "\n",
    "@ct.electron\n",
    "def define_optimizer():\n",
    "    opt = qml.AdamOptimizer(stepsize=0.01)\n",
    "    return opt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "@ct.electron\n",
    "def make_predictions(X_test, params):\n",
    "    test_predictions = []\n",
    "    for x_test in X_test:\n",
    "        prediction = quantum_circuit(x_test,params)\n",
    "        test_predictions.append(prediction)\n",
    "    return test_predictions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "@ct.electron\n",
    "def plot_results(X, Y, X_test, Y_test, predictions):\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.scatter(X, Y, c='#219ebc', label='Training data')\n",
    "    ax1.scatter(X_test,Y_test, c='#fb8500', label='Test data')\n",
    "    ax1.scatter(X_test,predictions, s=30, c='k', marker=\"x\", label='Model Predicitons')\n",
    "    plt.xlabel(\"Inputs\")\n",
    "    plt.ylabel(\"Outputs\")\n",
    "    plt.title(\"QML results\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig('predictions.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "'''\n",
    "red_data = reduce_data(data=data, n=10)\n",
    "X, Y, X_test, Y_test = train_test_split(red_data, 0.5)\n",
    "@ct.lattice\n",
    "@ct.electron\n",
    "def optimize(X, opt):\n",
    "    #opt = define_optimizer()\n",
    "    params = np.array([0.01,0.01,0.01],requires_grad=True)\n",
    "    for i in range (200):\n",
    "        params = update_parameters(opt, params)\n",
    "    return params\n",
    "\n",
    "@ct.lattice\n",
    "def workflow(X_train, Y_train, X_test, Y_test):\n",
    "    X, Y, X_test, Y_test = train_test_split(red_data, 0.5)\n",
    "    opt = define_optimizer()\n",
    "    params = optimize(X=X, opt=opt)\n",
    "    predictions = make_predictions(X_test=X_test, params=params)\n",
    "    plot_results(X, Y, X_test, Y_test, predictions)\n",
    "'''"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nred_data = reduce_data(data=data, n=10)\\nX, Y, X_test, Y_test = train_test_split(red_data, 0.5)\\n@ct.lattice\\n@ct.electron\\ndef optimize(X, opt):\\n    #opt = define_optimizer()\\n    params = np.array([0.01,0.01,0.01],requires_grad=True)\\n    for i in range (200):\\n        params = update_parameters(opt, params)\\n    return params\\n\\n@ct.lattice\\ndef workflow(X_train, Y_train, X_test, Y_test):\\n    X, Y, X_test, Y_test = train_test_split(red_data, 0.5)\\n    opt = define_optimizer()\\n    params = optimize(X=X, opt=opt)\\n    predictions = make_predictions(X_test=X_test, params=params)\\n    plot_results(X, Y, X_test, Y_test, predictions)\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "@ct.lattice\n",
    "@ct.electron\n",
    "def optimize(X_train, Y_train, opt):\n",
    "    Y_train = Y_train\n",
    "    X_train = X_train\n",
    "    params = np.array([0.01,0.01,0.01],requires_grad=True)\n",
    "    for i in range (200):\n",
    "        params = update_parameters(opt, params, quantum_circuit)\n",
    "    return params\n",
    "\n",
    "\n",
    "data = np.loadtxt('gauss.txt', delimiter=',')\n",
    "@ct.lattice\n",
    "def miniworkflow():\n",
    "    red_data = reduce_data(data=data, n=10)\n",
    "    X_train, Y_train, X_test, Y_test = train_test_split(data=red_data, train_portion=0.5)\n",
    "    opt = define_optimizer()\n",
    "    params = optimize(X_train=X_train, Y_train=Y_train, opt=opt)\n",
    "    predictions = make_predictions(X_test=X_test, params=params)\n",
    "    plot_results(X_train, Y_train, X_test, Y_test, predictions)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "ct.dispatch(miniworkflow)()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/annahughes/demonstration/covalent/covalent/_workflow/lattice.py:158: UserWarning: Please make sure you are not manipulating an object inside the lattice.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9t/njfmn3w11f159zbw1hpsjzn00000gn/T/ipykernel_4141/4101867922.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminiworkflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/demonstration/covalent/covalent/_dispatcher_plugins/local.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mlattice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_lattice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mlattice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m# Serializing the transport graph and then passing it to the Result object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/demonstration/covalent/covalent/_workflow/lattice.py\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mactive_lattice_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclaim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                     warnings.warn(\n",
      "\u001b[0;32m/var/folders/9t/njfmn3w11f159zbw1hpsjzn00000gn/T/ipykernel_4141/2900846733.py\u001b[0m in \u001b[0;36mminiworkflow\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#params = workflow(X, Y, X_test, Y_test)\n",
    "#print(params)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#ct.dispatch(workflow)(X, Y, X_test, Y_test)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('covalent_env': conda)"
  },
  "interpreter": {
   "hash": "570ca153600493184bf96a1606a53850814bca4f88e49a285286a552c69ae0c5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}