{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import covalent as ct\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, ParameterGrid\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = ct.executor.SlurmExecutor(username=\"venkat\", address=\"beehive.agnostiq.ai\", poll_freq=20,\n",
    "    conda_env=\"covalent\", ssh_key_file=\"~/.ssh/id_ed25519\",\n",
    "    remote_workdir=\"/federation/venkat\",\n",
    "    options={\n",
    "        \"ntasks\": 1,\n",
    "        \"cpus-per-task\": 2,\n",
    "        \"partition\": \"debug\",\n",
    "        \"nodelist\": \"beehive-debug-st-t2medium-1\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    boston = load_boston()\n",
    "    data = pd.DataFrame(boston.data)\n",
    "    data['PRICE'] = boston.target\n",
    "    X, y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "    return X, y\n",
    "\n",
    "def split_dataset(features: pd.DataFrame, targets: pd.DataFrame):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def get_model(params: dict):\n",
    "    return xgb.XGBRegressor(**params)\n",
    "\n",
    "def train(model: xgb.XGBModel, features: np.ndarray, targets: np.ndarray):\n",
    "    model.fit(features, targets)\n",
    "    return model\n",
    "\n",
    "def predict(model: xgb.XGBModel, features: np.ndarray):\n",
    "    return model.predict(features)\n",
    "\n",
    "def measure_model_performance(targets: np.ndarray, predictions: np.ndarray):\n",
    "    return np.sqrt(mean_squared_error(targets, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local execution withouth covalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 10.915755\n"
     ]
    }
   ],
   "source": [
    "X, y = load_dataset()\n",
    "X_train, X_test, y_train, y_test = split_dataset(X, y)\n",
    "model_to_train = get_model({\"objective\":\"reg:squarederror\",\n",
    "                                \"colsample_bytree\":0.3,\n",
    "                                \"learning_rate\": 0.1,\n",
    "                                \"max_depth\":5,\n",
    "                                \"alpha\": 10,\n",
    "                                \"n_estimators\": 10})\n",
    "trained_model= train(model_to_train, X_train, y_train)\n",
    "predictions = trained_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(\"RMSE: %f\"%(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def split_dataset(features: pd.DataFrame, targets: pd.DataFrame):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=123)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "@ct.electron\n",
    "def get_model(params: dict):\n",
    "    return xgb.XGBRegressor(**params)\n",
    "\n",
    "@ct.electron\n",
    "def train(model: xgb.XGBModel, features, targets):\n",
    "    print(type(model))\n",
    "    model.fit(features, targets)\n",
    "    return model\n",
    "\n",
    "@ct.electron\n",
    "def predict(model: xgb.XGBModel, features: np.ndarray):\n",
    "    return model.predict(features)\n",
    "\n",
    "@ct.electron\n",
    "def measure_model_performance(targets: np.ndarray, predictions: np.ndarray):\n",
    "    return np.sqrt(mean_squared_error(targets, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.lattice\n",
    "def workflow(X, y):\n",
    "    X_train, X_test, y_train, y_test = split_dataset(X, y)\n",
    "    model_to_train = get_model({\"objective\":\"reg:squarederror\",\n",
    "                                \"colsample_bytree\":0.3,\n",
    "                                \"learning_rate\": 0.1,\n",
    "                                \"max_depth\":5,\n",
    "                                \"alpha\": 10,\n",
    "                                \"n_estimators\": 10})\n",
    "    trained_model = train(model_to_train, X_train, y_train)\n",
    "    predictions = predict(trained_model, X_test)\n",
    "    score = measure_model_performance(y_test, predictions)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lattice Result\n",
      "==============\n",
      "status: FAILED\n",
      "result: None\n",
      "inputs: {'args': [           0     1      2    3      4      5     6       7    8      9    10  \\\n",
      "0    0.00632  18.0   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
      "1    0.02731   0.0   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
      "2    0.02729   0.0   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
      "3    0.03237   0.0   2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
      "4    0.06905   0.0   2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
      "..       ...   ...    ...  ...    ...    ...   ...     ...  ...    ...   ...   \n",
      "501  0.06263   0.0  11.93  0.0  0.573  6.593  69.1  2.4786  1.0  273.0  21.0   \n",
      "502  0.04527   0.0  11.93  0.0  0.573  6.120  76.7  2.2875  1.0  273.0  21.0   \n",
      "503  0.06076   0.0  11.93  0.0  0.573  6.976  91.0  2.1675  1.0  273.0  21.0   \n",
      "504  0.10959   0.0  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0  21.0   \n",
      "505  0.04741   0.0  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0  21.0   \n",
      "\n",
      "         11    12  \n",
      "0    396.90  4.98  \n",
      "1    396.90  9.14  \n",
      "2    392.83  4.03  \n",
      "3    394.63  2.94  \n",
      "4    396.90  5.33  \n",
      "..      ...   ...  \n",
      "501  391.99  9.67  \n",
      "502  396.90  9.08  \n",
      "503  396.90  5.64  \n",
      "504  393.45  6.48  \n",
      "505  396.90  7.88  \n",
      "\n",
      "[506 rows x 13 columns], 0      24.0\n",
      "1      21.6\n",
      "2      34.7\n",
      "3      33.4\n",
      "4      36.2\n",
      "       ... \n",
      "501    22.4\n",
      "502    20.6\n",
      "503    23.9\n",
      "504    22.0\n",
      "505    11.9\n",
      "Name: PRICE, Length: 506, dtype: float64], 'kwargs': {}}\n",
      "error: None\n",
      "\n",
      "start_time: 2022-04-20 16:46:58.150977+00:00\n",
      "end_time: 2022-04-20 16:47:18.079271+00:00\n",
      "\n",
      "results_dir: /tmp\n",
      "dispatch_id: 25eae71b-01f7-4825-bf8e-ee1408081a19\n",
      "\n",
      "Node Outputs\n",
      "------------\n",
      "split_dataset(0): (           0     1      2    3       4      5      6       7     8      9  \\\n",
      "203  0.03510  95.0   2.68  0.0  0.4161  7.853   33.2  5.1180   4.0  224.0   \n",
      "441  9.72418   0.0  18.10  0.0  0.7400  6.406   97.2  2.0651  24.0  666.0   \n",
      "172  0.13914   0.0   4.05  0.0  0.5100  5.572   88.5  2.5961   5.0  296.0   \n",
      "95   0.12204   0.0   2.89  0.0  0.4450  6.625   57.8  3.4952   2.0  276.0   \n",
      "54   0.01360  75.0   4.00  0.0  0.4100  5.888   47.6  7.3197   3.0  469.0   \n",
      "..       ...   ...    ...  ...     ...    ...    ...     ...   ...    ...   \n",
      "98   0.08187   0.0   2.89  0.0  0.4450  7.820   36.9  3.4952   2.0  276.0   \n",
      "476  4.87141   0.0  18.10  0.0  0.6140  6.484   93.6  2.3053  24.0  666.0   \n",
      "322  0.35114   0.0   7.38  0.0  0.4930  6.041   49.9  4.7211   5.0  287.0   \n",
      "382  9.18702   0.0  18.10  0.0  0.7000  5.536  100.0  1.5804  24.0  666.0   \n",
      "365  4.55587   0.0  18.10  0.0  0.7180  3.561   87.9  1.6132  24.0  666.0   \n",
      "\n",
      "       10      11     12  \n",
      "203  14.7  392.78   3.81  \n",
      "441  20.2  385.96  19.52  \n",
      "172  16.6  396.90  14.69  \n",
      "95   18.0  357.98   6.65  \n",
      "54   21.1  396.90  14.80  \n",
      "..    ...     ...    ...  \n",
      "98   18.0  393.53   3.57  \n",
      "476  20.2  396.21  18.68  \n",
      "322  19.6  396.90   7.70  \n",
      "382  20.2  396.90  23.60  \n",
      "365  20.2  354.70   7.12  \n",
      "\n",
      "[404 rows x 13 columns],             0     1      2    3       4      5      6       7     8      9  \\\n",
      "410  51.13580   0.0  18.10  0.0  0.5970  5.757  100.0  1.4130  24.0  666.0   \n",
      "85    0.05735   0.0   4.49  0.0  0.4490  6.630   56.1  4.4377   3.0  247.0   \n",
      "280   0.03578  20.0   3.33  0.0  0.4429  7.820   64.5  4.6947   5.0  216.0   \n",
      "422  12.04820   0.0  18.10  0.0  0.6140  5.648   87.6  1.9512  24.0  666.0   \n",
      "199   0.03150  95.0   1.47  0.0  0.4030  6.975   15.3  7.6534   3.0  402.0   \n",
      "..        ...   ...    ...  ...     ...    ...    ...     ...   ...    ...   \n",
      "229   0.44178   0.0   6.20  0.0  0.5040  6.552   21.4  3.3751   8.0  307.0   \n",
      "159   1.42502   0.0  19.58  0.0  0.8710  6.510  100.0  1.7659   5.0  403.0   \n",
      "196   0.04011  80.0   1.52  0.0  0.4040  7.287   34.1  7.3090   2.0  329.0   \n",
      "345   0.03113   0.0   4.39  0.0  0.4420  6.014   48.5  8.0136   3.0  352.0   \n",
      "467   4.42228   0.0  18.10  0.0  0.5840  6.003   94.5  2.5403  24.0  666.0   \n",
      "\n",
      "       10      11     12  \n",
      "410  20.2    2.60  10.11  \n",
      "85   18.5  392.30   6.53  \n",
      "280  14.9  387.31   3.76  \n",
      "422  20.2  291.55  14.10  \n",
      "199  17.0  396.90   4.56  \n",
      "..    ...     ...    ...  \n",
      "229  17.4  380.34   3.76  \n",
      "159  14.7  364.31   7.39  \n",
      "196  12.6  396.90   4.08  \n",
      "345  18.8  385.64  10.53  \n",
      "467  20.2  331.29  21.32  \n",
      "\n",
      "[102 rows x 13 columns], 203    48.5\n",
      "441    17.1\n",
      "172    23.1\n",
      "95     28.4\n",
      "54     18.9\n",
      "       ... \n",
      "98     43.8\n",
      "476    16.7\n",
      "322    20.4\n",
      "382    11.3\n",
      "365    27.5\n",
      "Name: PRICE, Length: 404, dtype: float64, 410    15.0\n",
      "85     26.6\n",
      "280    45.4\n",
      "422    20.8\n",
      "199    34.9\n",
      "       ... \n",
      "229    31.5\n",
      "159    23.3\n",
      "196    33.3\n",
      "345    17.5\n",
      "467    19.1\n",
      "Name: PRICE, Length: 102, dtype: float64)\n",
      ":parameter:           0     1      2    3      4      5     6       7    8      9    10  \\\n",
      "0    0.00632  18.0   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
      "1    0.02731   0.0   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
      "2    0.02729   0.0   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
      "3    0.03237   0.0   2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
      "4    0.06905   0.0   2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
      "..       ...   ...    ...  ...    ...    ...   ...     ...  ...    ...   ...   \n",
      "501  0.06263   0.0  11.93  0.0  0.573  6.593  69.1  2.4786  1.0  273.0  21.0   \n",
      "502  0.04527   0.0  11.93  0.0  0.573  6.120  76.7  2.2875  1.0  273.0  21.0   \n",
      "503  0.06076   0.0  11.93  0.0  0.573  6.976  91.0  2.1675  1.0  273.0  21.0   \n",
      "504  0.10959   0.0  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0  21.0   \n",
      "505  0.04741   0.0  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0  21.0   \n",
      "\n",
      "         11    12  \n",
      "0    396.90  4.98  \n",
      "1    396.90  9.14  \n",
      "2    392.83  4.03  \n",
      "3    394.63  2.94  \n",
      "4    396.90  5.33  \n",
      "..      ...   ...  \n",
      "501  391.99  9.67  \n",
      "502  396.90  9.08  \n",
      "503  396.90  5.64  \n",
      "504  393.45  6.48  \n",
      "505  396.90  7.88  \n",
      "\n",
      "[506 rows x 13 columns](1)(1):            0     1      2    3      4      5     6       7    8      9    10  \\\n",
      "0    0.00632  18.0   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
      "1    0.02731   0.0   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
      "2    0.02729   0.0   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
      "3    0.03237   0.0   2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
      "4    0.06905   0.0   2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
      "..       ...   ...    ...  ...    ...    ...   ...     ...  ...    ...   ...   \n",
      "501  0.06263   0.0  11.93  0.0  0.573  6.593  69.1  2.4786  1.0  273.0  21.0   \n",
      "502  0.04527   0.0  11.93  0.0  0.573  6.120  76.7  2.2875  1.0  273.0  21.0   \n",
      "503  0.06076   0.0  11.93  0.0  0.573  6.976  91.0  2.1675  1.0  273.0  21.0   \n",
      "504  0.10959   0.0  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0  21.0   \n",
      "505  0.04741   0.0  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0  21.0   \n",
      "\n",
      "         11    12  \n",
      "0    396.90  4.98  \n",
      "1    396.90  9.14  \n",
      "2    392.83  4.03  \n",
      "3    394.63  2.94  \n",
      "4    396.90  5.33  \n",
      "..      ...   ...  \n",
      "501  391.99  9.67  \n",
      "502  396.90  9.08  \n",
      "503  396.90  5.64  \n",
      "504  393.45  6.48  \n",
      "505  396.90  7.88  \n",
      "\n",
      "[506 rows x 13 columns]\n",
      ":parameter:0      24.0\n",
      "1      21.6\n",
      "2      34.7\n",
      "3      33.4\n",
      "4      36.2\n",
      "       ... \n",
      "501    22.4\n",
      "502    20.6\n",
      "503    23.9\n",
      "504    22.0\n",
      "505    11.9\n",
      "Name: PRICE, Length: 506, dtype: float64(2)(2): 0      24.0\n",
      "1      21.6\n",
      "2      34.7\n",
      "3      33.4\n",
      "4      36.2\n",
      "       ... \n",
      "501    22.4\n",
      "502    20.6\n",
      "503    23.9\n",
      "504    22.0\n",
      "505    11.9\n",
      "Name: PRICE, Length: 506, dtype: float64\n",
      ":generated:split_dataset()[0](3)(3):            0     1      2    3       4      5      6       7     8      9  \\\n",
      "203  0.03510  95.0   2.68  0.0  0.4161  7.853   33.2  5.1180   4.0  224.0   \n",
      "441  9.72418   0.0  18.10  0.0  0.7400  6.406   97.2  2.0651  24.0  666.0   \n",
      "172  0.13914   0.0   4.05  0.0  0.5100  5.572   88.5  2.5961   5.0  296.0   \n",
      "95   0.12204   0.0   2.89  0.0  0.4450  6.625   57.8  3.4952   2.0  276.0   \n",
      "54   0.01360  75.0   4.00  0.0  0.4100  5.888   47.6  7.3197   3.0  469.0   \n",
      "..       ...   ...    ...  ...     ...    ...    ...     ...   ...    ...   \n",
      "98   0.08187   0.0   2.89  0.0  0.4450  7.820   36.9  3.4952   2.0  276.0   \n",
      "476  4.87141   0.0  18.10  0.0  0.6140  6.484   93.6  2.3053  24.0  666.0   \n",
      "322  0.35114   0.0   7.38  0.0  0.4930  6.041   49.9  4.7211   5.0  287.0   \n",
      "382  9.18702   0.0  18.10  0.0  0.7000  5.536  100.0  1.5804  24.0  666.0   \n",
      "365  4.55587   0.0  18.10  0.0  0.7180  3.561   87.9  1.6132  24.0  666.0   \n",
      "\n",
      "       10      11     12  \n",
      "203  14.7  392.78   3.81  \n",
      "441  20.2  385.96  19.52  \n",
      "172  16.6  396.90  14.69  \n",
      "95   18.0  357.98   6.65  \n",
      "54   21.1  396.90  14.80  \n",
      "..    ...     ...    ...  \n",
      "98   18.0  393.53   3.57  \n",
      "476  20.2  396.21  18.68  \n",
      "322  19.6  396.90   7.70  \n",
      "382  20.2  396.90  23.60  \n",
      "365  20.2  354.70   7.12  \n",
      "\n",
      "[404 rows x 13 columns]\n",
      ":generated:split_dataset()[1](4)(4):             0     1      2    3       4      5      6       7     8      9  \\\n",
      "410  51.13580   0.0  18.10  0.0  0.5970  5.757  100.0  1.4130  24.0  666.0   \n",
      "85    0.05735   0.0   4.49  0.0  0.4490  6.630   56.1  4.4377   3.0  247.0   \n",
      "280   0.03578  20.0   3.33  0.0  0.4429  7.820   64.5  4.6947   5.0  216.0   \n",
      "422  12.04820   0.0  18.10  0.0  0.6140  5.648   87.6  1.9512  24.0  666.0   \n",
      "199   0.03150  95.0   1.47  0.0  0.4030  6.975   15.3  7.6534   3.0  402.0   \n",
      "..        ...   ...    ...  ...     ...    ...    ...     ...   ...    ...   \n",
      "229   0.44178   0.0   6.20  0.0  0.5040  6.552   21.4  3.3751   8.0  307.0   \n",
      "159   1.42502   0.0  19.58  0.0  0.8710  6.510  100.0  1.7659   5.0  403.0   \n",
      "196   0.04011  80.0   1.52  0.0  0.4040  7.287   34.1  7.3090   2.0  329.0   \n",
      "345   0.03113   0.0   4.39  0.0  0.4420  6.014   48.5  8.0136   3.0  352.0   \n",
      "467   4.42228   0.0  18.10  0.0  0.5840  6.003   94.5  2.5403  24.0  666.0   \n",
      "\n",
      "       10      11     12  \n",
      "410  20.2    2.60  10.11  \n",
      "85   18.5  392.30   6.53  \n",
      "280  14.9  387.31   3.76  \n",
      "422  20.2  291.55  14.10  \n",
      "199  17.0  396.90   4.56  \n",
      "..    ...     ...    ...  \n",
      "229  17.4  380.34   3.76  \n",
      "159  14.7  364.31   7.39  \n",
      "196  12.6  396.90   4.08  \n",
      "345  18.8  385.64  10.53  \n",
      "467  20.2  331.29  21.32  \n",
      "\n",
      "[102 rows x 13 columns]\n",
      ":generated:split_dataset()[2](5)(5): 203    48.5\n",
      "441    17.1\n",
      "172    23.1\n",
      "95     28.4\n",
      "54     18.9\n",
      "       ... \n",
      "98     43.8\n",
      "476    16.7\n",
      "322    20.4\n",
      "382    11.3\n",
      "365    27.5\n",
      "Name: PRICE, Length: 404, dtype: float64\n",
      ":generated:split_dataset()[3](6)(6): 410    15.0\n",
      "85     26.6\n",
      "280    45.4\n",
      "422    20.8\n",
      "199    34.9\n",
      "       ... \n",
      "229    31.5\n",
      "159    23.3\n",
      "196    33.3\n",
      "345    17.5\n",
      "467    19.1\n",
      "Name: PRICE, Length: 102, dtype: float64\n",
      "get_model(7): XGBRegressor(alpha=10, base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=0.3, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, gamma=None,\n",
      "             gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=10, n_jobs=None,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None,\n",
      "             reg_alpha=None, ...)\n",
      ":electron_dict:(8): {'objective': 'reg:squarederror', 'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 5, 'alpha': 10, 'n_estimators': 10}\n",
      ":parameter:reg:squarederror(9)(9): reg:squarederror\n",
      ":parameter:0.3(10)(10): 0.3\n",
      ":parameter:0.1(11)(11): 0.1\n",
      ":parameter:5(12)(12): 5\n",
      ":parameter:10(13)(13): 10\n",
      ":parameter:10(14)(14): 10\n",
      "train(15): None\n",
      "predict(16): None\n",
      "measure_model_performance(17): None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = load_dataset()\n",
    "dispatch_id = ct.dispatch(workflow)(X, y)\n",
    "result = ct.get_result(dispatch_id=dispatch_id, wait=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_tune={\n",
    "    \"colsample_bytree\": np.linspace(0.1, 0.5, 5),\n",
    "    \"learning_rate\": np.linspace(0.01, 0.1, 5),\n",
    "    \"max_depth\": [5, 9, 10],\n",
    "    \"alpha\": np.arange(5, 11, 2),\n",
    "    \"n_estimators\": np.arange(8, 11, 1)\n",
    "}\n",
    "\n",
    "# Get a list of all parameters to use to build a model and cross validate\n",
    "grid = list(ParameterGrid(params_to_tune))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = list()\n",
    "scores_std = list()\n",
    "for p in grid:\n",
    "    model = xgb.XGBRegressor(objective=\"reg:squarederror\", **p)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, scoring='neg_root_mean_squared_error', cv=3)\n",
    "    scores.append(np.mean(cv_scores))\n",
    "    scores_std.append(np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use covalent to dispatch to Slurm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study model performance as a function of the tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsample_bytree_values = []\n",
    "n_estimator_values = []\n",
    "learning_rate_values = []\n",
    "max_depth_values = []\n",
    "alpha_values = []\n",
    "for p in grid:\n",
    "    colsample_bytree_values.append(p['colsample_bytree'])\n",
    "    learning_rate_values.append(p['learning_rate'])\n",
    "    max_depth_values.append(p['max_depth'])\n",
    "    alpha_values.append(p['alpha'])\n",
    "    n_estimator_values.append(p['n_estimators'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group scores with colsample_bytree parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for colsample, score in zip(colsample_bytree_values, scores):\n",
    "    entry = {'colsample_bytree': colsample, 'score': score}\n",
    "    temp.append(entry)\n",
    "df = pd.DataFrame(temp)\n",
    "temp2 = []\n",
    "for unique in np.unique(colsample_bytree_values):\n",
    "    entry = {'colsample_bytree': unique, 'avg_score': np.mean(df[df['colsample_bytree'] == unique]['score'])}\n",
    "    temp2.append(entry)\n",
    "df_colsample_bytree_vs_scores = pd.DataFrame(temp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group scores with learning_rate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for lrate, score in zip(learning_rate_values, scores):\n",
    "    entry = {'learning_rate': lrate, 'score': score}\n",
    "    temp.append(entry)\n",
    "df = pd.DataFrame(temp)\n",
    "temp2 = []\n",
    "for unique in np.unique(learning_rate_values):\n",
    "    entry = {'learning_rate': unique, 'avg_score': np.mean(df[df['learning_rate'] == unique]['score'])}\n",
    "    temp2.append(entry)\n",
    "df_learning_rate_vs_scores = pd.DataFrame(temp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group scores with alpha values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for alpha, score in zip(alpha_values, scores):\n",
    "    entry = {'alpha': alpha, 'score': score}\n",
    "    temp.append(entry)\n",
    "df = pd.DataFrame(temp)\n",
    "temp2 = []\n",
    "for unique in np.unique(alpha_values):\n",
    "    entry = {'alpha': unique, 'avg_score': np.mean(df[df['alpha'] == unique]['score'])}\n",
    "    temp2.append(entry)\n",
    "df_alpha_vs_scores = pd.DataFrame(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(df_colsample_bytree_vs_scores['colsample_bytree'], df_colsample_bytree_vs_scores['avg_score'], 'o-', ms=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(df_learning_rate_vs_scores['learning_rate'], df_learning_rate_vs_scores['avg_score'], 'o-', ms=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(df_alpha_vs_scores['alpha'], df_alpha_vs_scores['avg_score'], 'o-', ms=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd8d132f2c9868f0de786af45cb93a5aab017a81263068ec051dedbc1ccb266a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cova')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
