{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create a custom executor\n",
    "\n",
    "<font size=\"3\">\n",
    "\n",
    "_Executors_ define the low-level directions for the computation. They can specify different capabilities, _eg_, different hardware, different computation strategy, different logic, or simply different goals.\n",
    "\n",
    "Executors are plugins; any executor-plugins which are found are imported as classes in the covalent.executor name-space.\n",
    "See the how-to on [choosing an executor to be used in an electron](choosing_executors.ipynb) for details on simply choosing an executor.\n",
    "    \n",
    "You can write your own executor to execute Covalent electrons in any way you like, using particular environments, cloud resources, or hardware.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "\n",
    "Start by cloning the [executor template](https://github.com/AgnostiqHQ/covalent-executor-template).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/AgnostiqHQ/covalent-executor-template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "\n",
    "Rename `covalent_executor_template` and `custom.py`\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('covalent-executor-template')\n",
    "!mv covalent_executor_template covalent_mycustom_plugin\n",
    "!mv covalent_mycustom_plugin/custom.py covalent_mycustom_plugin/mycustom.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "\n",
    "In `setup.py`, modify `plugins_list` and `setup_info` to reflect the name of your executor plugin.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import site\n",
    "import sys\n",
    "\n",
    "from setuptools import find_packages, setup\n",
    "\n",
    "with open(\"VERSION\") as f:\n",
    "    version = f.read().strip()\n",
    "    \n",
    "with open(\"requirements.txt\") as f:\n",
    "    required = f.read().splitlines()\n",
    "\n",
    "# Modify this to be the name of your plugin file. Here, \"covalent_executor_template\"\n",
    "# is the name of the directory the plugin is in. \"custom\" is name of the module.\n",
    "plugins_list = [\"mycustom = covalent_mycustom_plugin.mycustom\"]\n",
    "\n",
    "setup_info = {\n",
    "    # Your plugin should use the naming convention 'covalent-abcdef-plugin'\n",
    "    \"name\": \"covalent-mycustom-plugin\",\n",
    "    \"packages\": find_packages(\".\"),\n",
    "    \"version\": version,\n",
    "    # Modify any contact information as you see fit\n",
    "    \"maintainer\": \"Agnostiq\",\n",
    "    \"url\": \"https://github.com/AgnostiqHQ/covalent-executor-template\",\n",
    "    \"download_url\": f\"https://github.com/AgnostiqHQ/covalent-executor-template/archive/v{version}.tar.gz\",\n",
    "    \"license\": \"GNU Affero GPL v3.0\",\n",
    "    \"author\": \"Agnostiq\",\n",
    "    \"author_email\": \"support@agnostiq.ai\",\n",
    "    \"description\": \"Covalent Custom Executor Plugin\",\n",
    "    \"long_description\": open(\"README.md\").read(),\n",
    "    \"long_description_content_type\": \"text/markdown\",\n",
    "    \"include_package_data\": True,\n",
    "    \"install_requires\": required,\n",
    "    \"classifiers\": [\n",
    "        \"Development Status :: 3 - Alpha\",\n",
    "        \"Environment :: Console\",\n",
    "        \"Environment :: Plugins\",\n",
    "        \"Intended Audience :: Developers\",\n",
    "        \"Intended Audience :: Education\",\n",
    "        \"Intended Audience :: Science/Research\",\n",
    "        \"License :: Other/Proprietary License\",\n",
    "        \"Natural Language :: English\",\n",
    "        \"Operating System :: MacOS\",\n",
    "        \"Operating System :: POSIX :: Linux\",\n",
    "        \"Programming Language :: Python :: 3\",\n",
    "        \"Programming Language :: Python :: 3 :: Only\",\n",
    "        \"Programming Language :: Python :: 3.8\",\n",
    "        \"Programming Language :: Python :: 3.9\",\n",
    "        \"Topic :: Adaptive Technologies\",\n",
    "        \"Topic :: Scientific/Engineering\",\n",
    "        \"Topic :: Scientific/Engineering :: Interface Engine/Protocol Translator\",\n",
    "        \"Topic :: Software Development\",\n",
    "        \"Topic :: System :: Distributed Computing\",\n",
    "    ],\n",
    "    \"entry_points\": {\n",
    "        \"covalent.executor.executor_plugins\": plugins_list,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can write the execution logic in `mycustom.py`. You'll need to update `_EXECUTOR_PLUGIN_DEFAULTS`, `executor_plugin_name`, `CustomExecutor`, and `run()`. As an example, here we'll add logic to execute electrons in Docker containers. \n",
    "\n",
    "Here is a docker image that we will use later to launch containers and run electrons.\n",
    "```docker\n",
    "# Dockerfile\n",
    "FROM python:3.8-buster\n",
    "\n",
    "RUN pip install cloudpickle && \\\n",
    "    pip install covalent\n",
    "\n",
    "CMD [\"/bin/bash\"]\n",
    "```\n",
    "\n",
    "In this Dockerfile, we install the bare minimum dependencies required to execute electrons. Next we build an image `docker-executor-demo:latest` from the Dockerfile template to be used in our workflows.\n",
    "\n",
    "```shell\n",
    "docker build -f Dockerfile --tag docker-executor-demo:latest .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_EXECUTOR_PLUGIN_DEFAULTS = {\n",
    "    \"image\": \"python:3.8\",   # Default docker image to be used if not specified\n",
    "    \"workdir\": \".\", # Path to the working directory on disk where files generated during execution will be stored. Defaults to current working directory\n",
    "    \"options\": {}    # Any options supported by the docker run CLI\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor_plugin_name = 'DockerExecutor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `executor_plugin_name` must match the subclass name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from covalent.executor import BaseExecutor\n",
    "from typing import Any, Dict, List, Tuple, Callable\n",
    "import tempfile\n",
    "import cloudpickle as pickle\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "class DockerExecutor(BaseExecutor):\n",
    "    \"\"\"Docker executor plugin class\n",
    "    \n",
    "    Args:\n",
    "        :param str image: Name of the docker image to be used for running electrons.\n",
    "        :param str workdir: Path on the disk where files generated during execution will be created/stored.\n",
    "        :param dict options: Python dictionary of keyword arguments of the different options supported by the `docker run` CLI.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "        image: str,\n",
    "        workdir: str,\n",
    "        options: Dict = {},\n",
    "        container_workdir: str = \"/tmp/covalent\",  # Workdir inside the container\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        self.image = image\n",
    "        self.wordir = workdir\n",
    "        self.options = options\n",
    "        self._container_workdir = container_workdir\n",
    "\n",
    "        super().__init__(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command to be executed can be rendered as a multiline string. To this end, we create a method `_format_exec_command` in our `DockerExecutor` to facilitate generation of the `exec` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_exec_command(self, func_filename: str, result_filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a python string that can be used to execute the task inside the container\n",
    "\n",
    "    Args:\n",
    "        :param str func_filename: Name of the pickle file from which to read the function to be executed.\n",
    "        :param str result_filename: Name of the pickle file into which the serialize and write the task result\n",
    "\n",
    "    Returns:\n",
    "        :param str script: Python string that can be parsed to execute the function\n",
    "    \"\"\"\n",
    "    return \"\\n\".join(\n",
    "        [\n",
    "            \"import cloudpickle as pickle\",\n",
    "            \"\",\n",
    "            \"result = None\",\n",
    "            \"exception = None\",\n",
    "            \"\",\n",
    "            \"with open('{func_filename}', 'rb') as f:\",\n",
    "            \"   function, args, kwargs = pickle.load(f)\",\n",
    "            \"   try:\",\n",
    "            \"       result = function(*args, **kwargs)\",\n",
    "            \"   except Exception as e:\",\n",
    "            \"       exception = e\",\n",
    "            \"   finally:\",\n",
    "            \"       with open('{result_filename}', 'wb') as f_out:\",\n",
    "            \"           pickle.dump((result, exception), f_out)\",\n",
    "            \"\",\n",
    "        ]\n",
    "    ).format(\n",
    "        func_filename = os.path.join(self._container_workdir, func_filename),\n",
    "        result_filename = os.path.join(self._container_workdir, result_filename)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `_format_exec_command` helper method defined, we can now implement the executor's `run` method that contains the core logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(self,\n",
    "    function: Callable,\n",
    "    args: List,\n",
    "    kwargs: List,\n",
    "    task_metadata: Dict,\n",
    "):\n",
    "    \"\"\"\n",
    "        Execute the callable inside the respective container and return the result\n",
    "\n",
    "        Args:\n",
    "            :param Callable function: The input python function to be executed inside the container whose result is to be returned back\n",
    "            :param List args: List of positional arguments required by the function\n",
    "            :param Dict kwargs: Dictionary of keyword arguments required by the function\n",
    "            :param Dict task_metadata: Dictionary of metadata fields; as of now contains \"dispatch_id\" and \"node_id\"\n",
    "    \"\"\"\n",
    "\n",
    "    # set the necessary variables such as filenames to be used as part of the execution.\n",
    "    # Use the dispatch_id and the node_id in order to uniquely identify each file/container being\n",
    "    # created during execution\n",
    "    result_filename = f\"result-{task_metadata['dispatch_id']}-{task_metadata['node_id']}.pkl\"\n",
    "    container_name = f\"container-{task_metadata['dispatch_id']}-{task_metadata['node_id']}\"\n",
    "    execute_script_name = f\"dkrexec-{task_metadata['dispatch_id']}-{task_metadata['node_id']}.py\"\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(dir=self.workdir) as f, tempfile.NamedTemporaryFile(dir=self.workdir, mode=\"w\") as g:\n",
    "\n",
    "            pickle.dump((function, args, kwargs), f)\n",
    "            f.flush()\n",
    "\n",
    "            # Format the command to be executed inside the container\n",
    "            func_filename = f\"func-{task_metadata['dispatch_id']}-{task_metadata['node_id']}.pkl\"\n",
    "            shutil.copy(f.name, os.path.join(self.workdir, func_filename))\n",
    "\n",
    "            cmd = self.format_exec_command(func_filename, result_filename)\n",
    "            g.write(cmd)\n",
    "            g.flush()\n",
    "            shutil.copy(g.name, os.path.join(self.workdir, execute_script_name))\n",
    "\n",
    "            # Start the container in detached mode\n",
    "            subprocess.run(\n",
    "                [\n",
    "                    \"docker\",\n",
    "                    \"container\",\n",
    "                    \"run\",\n",
    "                    \"-dit\",\n",
    "                     \"--rm\",\n",
    "                    \"--mount\",\n",
    "                    f\"type=bind,source={self.workdir},target={self._container_workdir}\",\n",
    "                    \"--name\",\n",
    "                    container_name,\n",
    "                    self.image\n",
    "                ],\n",
    "                check=True,\n",
    "                capture_output=True,\n",
    "            )\n",
    "\n",
    "            # Execute the script/command inside the container\n",
    "            subprocess.run(\n",
    "                [\n",
    "                    \"docker\",\n",
    "                    \"container\",\n",
    "                    \"exec\",\n",
    "                    container_name,\n",
    "                    \"python\",\n",
    "                    f\"{self._container_workdir}/{execute_script_name}\"\n",
    "                ],\n",
    "                check=True,\n",
    "                capture_output=True\n",
    "            )\n",
    "\n",
    "            # Assert that a result object was created\n",
    "            assert os.path.exists(os.path.join(self.workdir, result_filename))\n",
    "\n",
    "            # Read the generated result object from the result pickle file\n",
    "            with open(os.path.join(self.workdir, result_filename), \"rb\") as f_read:\n",
    "                result, exception = pickle.load(f_read)\n",
    "                if exception:\n",
    "                    raise exception\n",
    "\n",
    "            # Terminate the container\n",
    "            subprocess.run(\n",
    "                [\n",
    "                    \"docker\",\n",
    "                    \"container\",\n",
    "                    \"stop\",\n",
    "                    container_name\n",
    "                ],\n",
    "                check=True,\n",
    "                capture_output=True\n",
    "            )\n",
    "\n",
    "            # Return\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, here is the entire executor as part of a single executable block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import shutil\n",
    "import cloudpickle as pickle\n",
    "import tempfile\n",
    "import subprocess\n",
    "from typing import List, Dict\n",
    "\n",
    "from covalent.executor import BaseExecutor\n",
    "from covalent._shared_files import logger\n",
    "\n",
    "app_log = logger.app_log\n",
    "log_stack_info = logger.log_stack_info\n",
    "\n",
    "_EXECUTOR_PLUGIN_DEFAULTS = {\n",
    "    \"image\": \"python:3.8\",   # Default docker image to be used if not specified\n",
    "    \"workdir\": \".\", # Path to the working directory on disk where files generated during execution will be        stored. Defaults to current working directory\n",
    "    \"options\": {},    # Any options supported by the docker run CLI\n",
    "}\n",
    "\n",
    "executor_plugin_name = 'DockerExecutor'\n",
    "\n",
    "class DockerExecutor(BaseExecutor):\n",
    "    \"\"\"Docker executor plugin class\n",
    "    \n",
    "    Args:\n",
    "        :param str image: Name of the docker image to be used for running electrons.\n",
    "        :param str workdir: Path on the disk where files generated during execution will be created/stored.\n",
    "        :param dict options: Python dictionary of keyword arguments of the different options supported by the `docker run` CLI.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "        image: str,\n",
    "        workdir: str,\n",
    "        options: Dict = {},\n",
    "        container_workdir: str = \"/tmp/covalent\",  # Workdir inside the container\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "\n",
    "        self.image = image\n",
    "        self.wordir = workdir\n",
    "        self.options = options\n",
    "        self._container_workdir = container_workdir\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def _format_exec_command(self, func_filename: str, result_filename: str) -> str:\n",
    "        \"\"\"\n",
    "        Create a python string that can be used to execute the task inside the container\n",
    "\n",
    "        Args:\n",
    "            :param str func_filename: Name of the pickle file from which to read the function to be executed.\n",
    "            :param str result_filename: Name of the pickle file into which the serialize and write the task result\n",
    "\n",
    "        Returns:\n",
    "            :param str script: Python string that can be parsed to execute the function\n",
    "        \"\"\"\n",
    "\n",
    "        return \"\\n\".join(\n",
    "            [\n",
    "                \"import cloudpickle as pickle\",\n",
    "                \"\",\n",
    "                \"result = None\",\n",
    "                \"exception = None\",\n",
    "                \"\",\n",
    "                \"with open('{func_filename}', 'rb') as f:\",\n",
    "                \"   function, args, kwargs = pickle.load(f)\",\n",
    "                \"   try:\",\n",
    "                \"       result = function(*args, **kwargs)\",\n",
    "                \"   except Exception as e:\",\n",
    "                \"       exception = e\",\n",
    "                \"   finally:\",\n",
    "                \"       with open('{result_filename}', 'wb') as f_out:\",\n",
    "                \"           pickle.dump((result, exception), f_out)\",\n",
    "                \"\",\n",
    "            ]\n",
    "        ).format(\n",
    "            func_filename = os.path.join(self._container_workdir, func_filename),\n",
    "            result_filename = os.path.join(self._container_workdir, result_filename)\n",
    "        )\n",
    "\n",
    "\n",
    "    def run(self,\n",
    "        function: Callable,\n",
    "        args: List,\n",
    "        kwargs: List,\n",
    "        task_metadata: Dict,\n",
    "    ):\n",
    "        \"\"\"\n",
    "            Execute the callable inside the respective container and return the result\n",
    "\n",
    "            Args:\n",
    "                :param Callable function: The input python function to be executed inside the container whose result is to be returned back\n",
    "                :param List args: List of positional arguments required by the function\n",
    "                :param Dict kwargs: Dictionary of keyword arguments required by the function\n",
    "                :param Dict task_metadata: Dictionary of metadata fields; as of now contains \"dispatch_id\" and \"node_id\"\n",
    "        \"\"\"\n",
    "\n",
    "        # set the necessary variables such as filenames to be used as part of the execution.\n",
    "        # Use the dispatch_id and the node_id in order to uniquely identify each file/container being\n",
    "        # created during execution\n",
    "        result_filename = f\"result-{task_metadata['dispatch_id']}-{task_metadata['node_id']}.pkl\"\n",
    "        container_name = f\"container-{task_metadata['dispatch_id']}-{task_metadata['node_id']}\"\n",
    "        execute_script_name = f\"dkrexec-{task_metadata['dispatch_id']}-{task_metadata['node_id']}.py\"\n",
    "\n",
    "        with tempfile.NamedTemporaryFile(dir=self.workdir) as f, tempfile.NamedTemporaryFile(dir=self.workdir, mode=\"w\") as g:\n",
    "\n",
    "                pickle.dump((function, args, kwargs), f)\n",
    "                f.flush()\n",
    "\n",
    "                # Format the command to be executed inside the container\n",
    "                func_filename = f\"func-{task_metadata['dispatch_id']}-{task_metadata['node_id']}.pkl\"\n",
    "                shutil.copy(f.name, os.path.join(self.workdir, func_filename))\n",
    "\n",
    "                cmd = self.format_exec_command(func_filename, result_filename)\n",
    "                g.write(cmd)\n",
    "                g.flush()\n",
    "                shutil.copy(g.name, os.path.join(self.workdir, execute_script_name))\n",
    "\n",
    "                # Start the container in detached mode\n",
    "                subprocess.run(\n",
    "                    [\n",
    "                        \"docker\",\n",
    "                        \"container\",\n",
    "                        \"run\",\n",
    "                        \"-dit\",\n",
    "                        \"--rm\",\n",
    "                        \"--mount\",\n",
    "                        f\"type=bind,source={self.workdir},target={self._container_workdir}\",\n",
    "                        \"--name\",\n",
    "                        container_name,\n",
    "                        self.image\n",
    "                    ],\n",
    "                    check=True,\n",
    "                    capture_output=True,\n",
    "                )\n",
    "\n",
    "                # Execute the script/command inside the container\n",
    "                subprocess.run(\n",
    "                    [\n",
    "                        \"docker\",\n",
    "                        \"container\",\n",
    "                        \"exec\",\n",
    "                        container_name,\n",
    "                        \"python\",\n",
    "                        f\"{self._container_workdir}/{execute_script_name}\"\n",
    "                    ],\n",
    "                    check=True,\n",
    "                    capture_output=True\n",
    "                )\n",
    "\n",
    "                # Assert that a result object was created\n",
    "                assert os.path.exists(os.path.join(self.workdir, result_filename))\n",
    "\n",
    "                # Read the generated result object from the result pickle file\n",
    "                with open(os.path.join(self.workdir, result_filename), \"rb\") as f_read:\n",
    "                    result, exception = pickle.load(f_read)\n",
    "                    if exception:\n",
    "                        raise exception\n",
    "\n",
    "                # Terminate the container\n",
    "                subprocess.run(\n",
    "                    [\n",
    "                        \"docker\",\n",
    "                        \"container\",\n",
    "                        \"stop\",\n",
    "                        container_name\n",
    "                    ],\n",
    "                    check=True,\n",
    "                    capture_output=True\n",
    "                )\n",
    "\n",
    "                # Return\n",
    "                return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This executor can now be used as part of workflows to execute electons inside Docker containers after being properly imported. Following is a quick example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import covalent as ct\n",
    "\n",
    "docker = DockerExecutor(image='docker-executor-demo:latest', workdir=os.getcwd())\n",
    "\n",
    "@ct.electron(executor=docker)\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "@ct.electron(executor=docker)\n",
    "def multiply(x, y):\n",
    "    return x*y\n",
    "\n",
    "\n",
    "@ct.lattice\n",
    "def workflow(x, y):\n",
    "    r1 = add(x, y)\n",
    "    return multiply(y, r1)\n",
    "\n",
    "result = ct.dispatch_sync(workflow)(2, 3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "Lattice Result\n",
    "==============\n",
    "status: COMPLETED\n",
    "result: 15\n",
    "inputs: {'args': [2, 3], 'kwargs': {}}\n",
    "error: None\n",
    "\n",
    "start_time: 2022-07-18 16:41:48.106224+00:00\n",
    "end_time: 2022-07-18 16:41:55.053115+00:00\n",
    "\n",
    "results_dir: results\n",
    "dispatch_id: 865fb0fd-7be3-4d15-a24d-97e5327b4253\n",
    "\n",
    "Node Outputs\n",
    "------------\n",
    "add(0): 5\n",
    ":parameter:2(1): 2\n",
    ":parameter:3(2): 3\n",
    "multiply(3): 15\n",
    ":parameter:3(4): 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('covadev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
